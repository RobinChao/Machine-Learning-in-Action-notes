{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章  决策树\n",
    "\n",
    "## 本章内容\n",
    "\n",
    "* 决策树简介\n",
    "* 在数据集中度量一致性\n",
    "* 使用递归构造决策树\n",
    "* 使用Matplotlib绘制树形图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 决策树 概述\n",
    "\n",
    "**决策树（Decision Tree）**算法是一种基本的分类和回归方法，是最经常使用的数据挖掘算法之一，但是这里我们先讨论用于**分类**的决策树。\n",
    "\n",
    "**决策树模型**：呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 **if-then**规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。\n",
    "\n",
    "**决策树**学习通常包含以下三个步骤：\n",
    "\n",
    "1. 特征选择\n",
    "2. 决策树生成\n",
    "3. 决策树修剪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 决策树 应用场景\n",
    "\n",
    "这里以一个经典的“二十个问题”的游戏描述开始：\n",
    "\n",
    "游戏规则：\n",
    "\n",
    "参与游戏的一方在脑海中构想一个事物，其他参与者向他提问，只允许提20个问题，问题的答案也只能用对或者错回答。问问题的人通过推断分解，逐步的缩小猜想事物的范围，最后得到游戏的答案 --- 是一个什么样的场景。\n",
    "\n",
    "\n",
    "另一个比较能说明问题的例子是邮件分类系统，大致工作流程如下：\n",
    "\n",
    "![](images/decision_tree_email.jpg)\n",
    "\n",
    "首先检测发送邮件的域名地址，如果地址为 myEmployer.com，则将其放在分类 “无聊时需要阅读的邮件”中。如果邮件不是来自这个域名，则检测邮件内容是否包含单词“曲棍球”，如果包含则将邮件归类到“需要及时处理的朋友邮件”，否则归类到“无需阅读的垃圾邮件”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 决策树 定义\n",
    "\n",
    "**分类决策树模型**是一种描述对实例进行分类的树形结构。决策树由节点（node）和有向边（directed edge）组成。节点有两种类型：\n",
    "\n",
    "* 内部节点（internal node）：表示一个特征或属性\n",
    "* 叶节点（leaf node）：表示一个类\n",
    "\n",
    "用决策树分类，从根节点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子节点，此时，每个子节点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶节点，最后将实例分配到到叶节点的类中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 决策树 工作原理\n",
    "\n",
    "**信息熵 & 信息增益**\n",
    "\n",
    "**熵（entropy）**：指的是体系的混乱程度，在不同的学科中也有引申出的更为具体的定义，是领域十分重要的参量。(后面详解)\n",
    "\n",
    "**信息熵（香农熵）**：是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。例如：火柴有序放在火柴盒里，熵值最低，相反，熵值很高。(后面详解)\n",
    "\n",
    "**信息增益**：在划分数据集前后信息发生的变化成为信息增益。(后面详解)\n",
    "\n",
    "**决策树构造**（伪代码）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*createBranch()*\n",
    "```\n",
    "检测数据集中每个子项是否属于同一分类：\n",
    "    If so return 类标签;\n",
    "    Else\n",
    "        寻找划分数据集的最好特征\n",
    "        划分数据集\n",
    "        创建分支点\n",
    "            for 每个划分的子集\n",
    "                调用构建决策树函数，并增加返回结果到分支节点中\n",
    "        return 分直节点\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 决策树 工作流程\n",
    "\n",
    "1. 收集数据：可以使用任何方法\n",
    "2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化\n",
    "3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图像是否符合预期\n",
    "4. 训练算法：构造树的数据结构\n",
    "5. 测试算法：使用经验树计算错误率\n",
    "6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 决策树 特点\n",
    "\n",
    "* **优点**：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据；\n",
    "* **缺点**：可能会产生过度匹配的问题\n",
    "* **使用数据类型**：数值型和标称型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 决策树 项目实践\n",
    "\n",
    "### 实践1： 判定是否是鱼类\n",
    "\n",
    "#### 项目概述\n",
    "\n",
    "根据以下两个特征，判断该动物是否为鱼类。\n",
    "\n",
    "特征：\n",
    "\n",
    "1. 不浮出水面是否可以生存\n",
    "2. 是否有脚蹼\n",
    "\n",
    "#### 开发流程\n",
    "\n",
    "1. 收集数据：可以使用任何方法\n",
    "2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化\n",
    "3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期\n",
    "4. 训练算法：构造树的数据结构\n",
    "5. 测试算法：使用决策树执行分类\n",
    "6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义\n",
    "\n",
    "**1. 收集数据**：可以使用任何方法\n",
    "\n",
    "假设我们得到的数据集如下：\n",
    "\n",
    "![](images/fish_or_not.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 准备数据**：树构造算法只适用于标称型数据，因此数值型数据必须离散化\n",
    "\n",
    "现在我们想要决定依据第一个特征还是第二个特征划分数据，但是在这之前，我们必须采用量化的方法判断如何划分数据。\n",
    "\n",
    "我们构建自己的 *createDataSet()* 方法，将标称型的数据离散化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 构建数据样本集（数据变化）\n",
    "def createDataSet():\n",
    "    dataSet = [\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no']\n",
    "    ]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 分析数据**：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期\n",
    "\n",
    "\n",
    "**3.1 信息增益（information gain）**\n",
    "\n",
    "划分数据集的大原则是：**将无序的数据变得更加有序。**\n",
    "组织杂乱无章数据的一种方法：**使用信息论度量信息，信息论是量化处理信息的分支科学。**\n",
    "\n",
    "**信息增益 定义**\n",
    "\n",
    "在划分数据之前后，信息发生的变化成为信息增益。\n",
    "\n",
    "**如何计算信息增益**\n",
    "\n",
    "**香农熵（简称熵）**：是集合信息的度量方式，定义为信息的期望值。\n",
    "\n",
    "**信息 定义**\n",
    "\n",
    "如果待分类的事物可能被划分在多个分类中，则符号$x_i$事物的信息定义为：\n",
    "\n",
    "$$l(x_i) = -\\log_2{p(x_i)}$$\n",
    "\n",
    "其中 $p(x_i)$ 是选择该分类的概率。\n",
    "\n",
    "但是为了计算熵，需要计算所有类别所有可能值包含的信息期望值，通过如下公式得到：\n",
    "\n",
    "$$H = -\\sum_{i=1}^{n}p(x_i)\\log_2{p(x_i)}$$\n",
    "\n",
    "其中$n$为分类的数目。\n",
    "\n",
    "了解了**香农熵**计算方式之后，我们来实现香农熵的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 计算给定数据集的香农熵的函数\n",
    "\n",
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    # 数据样本中的实例总数\n",
    "    numEntries = len(dataSet)\n",
    "    # 分类标签出现次数\n",
    "    labelCounts = {}\n",
    "    # 遍历数据集中每个特征向量\n",
    "    for featVec in dataSet:\n",
    "        # 获取分类标签\n",
    "        currentLabel = featVec[-1]\n",
    "        # 为所有可能的分类创建存储字典，如果当前键值不存在，则加入。每个键值记录了当前类别出现的次数\n",
    "        # key: 分类标签  value：出现的次数\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "        \n",
    "    # 对比标签的占比，求出标签的香农熵\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        # 使用所有分类标签的发生频率计算类别出现的概率\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        # 计算香农熵\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取熵之后，我们就可以按照获取最大信息增益的方法划分数据集了。\n",
    "\n",
    "> 还有一种度量数据无需程度的方法：**基尼不纯度(Gini impurity)**，简单地说就是从一个数据集中随机选取子项，度量其被错误分类到其他类别中的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 划分数据集**\n",
    "\n",
    "有了上面的知识储备后，我们就可以开始划分数据集并度量划分数据集的熵信息，判断是否正确划分数据集了。\n",
    "\n",
    "划分数据集的函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 按照给定的特征划分数据集\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"splitDataSet(通过遍历dataSet数据集，求出index对应的colnum列的值为value的行)\n",
    "        就是依据index列进行分类，如果index列的数据等于 value的时候，就要将 index 划分到我们创建的新的数据集中\n",
    "    Args:\n",
    "        dataSet 数据集                 待划分的数据集\n",
    "        axis 表示每一行的index列        划分数据集的特征\n",
    "        value 表示index列对应的value值   需要返回的特征的值。\n",
    "    Returns:\n",
    "        index列为value的数据集【该数据集需要排除index列】\n",
    "    \"\"\"\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        # 抽取axis列的值为value的数据\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            # extend 合并数据\n",
    "            reducedFeatVec.extend(featVec[axis + 1:])\n",
    "            # 追加到数据list中\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们将遍历整个数据集，循环计算香农熵和划分数据集，找到最好的特征划分方式，熵计算将会告诉我们如何划分数据集是最好的数据组织方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dataSet 数据集\n",
    "    Returns:\n",
    "        bestFeature 最优的特征列\n",
    "    \"\"\"\n",
    "    # 获取第一行有多少特征，由于最后一列是分类标签，因此数量-1\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    # label的信息熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    # 最优的信息增益值, 和最优的Featurn编号\n",
    "    bestInfoGain, bestFeature = 0.0, -1\n",
    "    # iterate over all the features\n",
    "    for i in range(numFeatures):\n",
    "        # create a list of all the examples of this feature\n",
    "        # 获取每一个实例的第i+1个feature，组成list集合\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        # get a set of unique values\n",
    "        # 获取剔重后的集合，使用set对list数据进行去重\n",
    "        uniqueVals = set(featList)\n",
    "        # 创建一个临时的信息熵\n",
    "        newEntropy = 0.0\n",
    "        # 遍历某一列的value集合，计算该列的信息熵 \n",
    "        # 遍历当前特征中的所有唯一属性值，对每个唯一属性值划分一次数据集，计算数据集的新熵值，并对所有唯一特征值得到的熵求和。\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        # gain[信息增益]: 划分数据集前后的信息变化， 获取信息熵最大的值\n",
    "        # 信息增益是熵的减少或者是数据无序度的减少。最后，比较所有特征中的信息增益，返回最好特征划分的索引值。\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print('infoGain=', infoGain, 'bestFeature=', i, baseEntropy, newEntropy)\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    print('bestFeature = ', bestFeature)\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，原始数据中，第0个特征是最好的用于划分数据集的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 训练算法**：构造树的数据结构\n",
    "\n",
    "从数据集构造决策树算法所需要的子功能模块已经完成了，其工作原理如下：\n",
    "\n",
    "* 得到原始数据集\n",
    "* 基于做好的属性值划分数据集\n",
    "    * 由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分\n",
    "* 首次划分后，数据将被向下传递到树分支的下一个节点\n",
    "* 根据实际情况，可再次划分数据\n",
    "\n",
    "因此我们可以采用递归的原则处理数据集。递归结束的条件是：\n",
    "\n",
    "**程序遍历完所有划分数据集的属性，或者每个分支下的所有实例都具有相同的分类。如果所有实例具有相同的分类，则得到一个叶子节点或者终止块。**\n",
    "\n",
    "如上述分类鱼类与非鱼类的例子描述，刻画出如下的数据路径：\n",
    "\n",
    "![](images/fish_data_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，有些情况下，我们处理了数据集所有的属性，但是类标签在叶子节点上依然不是唯一的，此时我们就需要采用多数表决的方式决定该叶子节点的分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分类表决决定叶子节点分类\n",
    "import operator\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    # 遍历所有的标签列表，统计标签数量\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    # 对统计结果进行排序\n",
    "    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.4199730940219749 bestFeature= 0 0.9709505944546686 0.5509775004326937\n",
      "infoGain= 0.17095059445466854 bestFeature= 1 0.9709505944546686 0.8\n",
      "bestFeature =  0\n",
      "infoGain= 0.9182958340544896 bestFeature= 0 0.9182958340544896 0.0\n",
      "bestFeature =  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建树的数据结构\n",
    "def createTree(dataSet, labels):\n",
    "    # 获取分类标签列表\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行\n",
    "    # 第一个停止条件：所有的类标签完全相同，则直接返回该类标签。\n",
    "    # count() 函数是统计括号中的值在list中出现的次数\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 如果数据集只有1列，那么最初出现label次数最多的一类，作为结果\n",
    "    # 第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "\n",
    "    # 选择最优的列，得到最优列对应的label含义\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    # 获取label的名称\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    # 初始化myTree\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    # 注：labels列表是可变对象，在PYTHON函数中作为参数时传址引用，能够被全局修改\n",
    "    # 所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list\n",
    "    del(labels[bestFeat])\n",
    "    # 取出最优列，然后它的branch做分类\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        # 求成剩余标签Label\n",
    "        subLabels = labels[:]\n",
    "        # 遍历当前选择的特征包含的所有属性，在每个数据集划分上递归调用createTree()\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "    return myTree\n",
    "\n",
    "import copy\n",
    "\n",
    "myDat, classL = createDataSet()\n",
    "myTree = createTree(myDat, copy.deepcopy(classL))\n",
    "myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用Matplotlib注解绘制树形图**\n",
    "\n",
    "**annitations**：Matplotlib提供的注解工具，可以附带文字、箭头等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADxCAYAAAD8x81kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFkIID/H/seM6KTKXpyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b03ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 附上最终代码\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义文本框 和 箭头格式 【 sawtooth 波浪方框, round4 矩形方框 , fc表示字体颜色的深浅 0.1~0.9 依次变浅，没错是变浅】\n",
    "decisionNode = dict(boxstyle=\"sawtooth\", fc=\"0.8\")\n",
    "leafNode = dict(boxstyle=\"round4\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"<-\")\n",
    "\n",
    "\n",
    "def getNumLeafs(myTree):\n",
    "    numLeafs = 0\n",
    "    firstSides = list(myTree.keys())\n",
    "    firstStr = firstSides[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    # 根节点开始遍历\n",
    "    for key in secondDict.keys():\n",
    "        # 判断子节点是否为dict, 不是+1\n",
    "        if type(secondDict[key]) is dict:\n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "        else:\n",
    "            numLeafs += 1\n",
    "    return numLeafs\n",
    "\n",
    "\n",
    "def getTreeDepth(myTree):\n",
    "    maxDepth = 0\n",
    "    firstSides = list(myTree.keys())\n",
    "    firstStr = firstSides[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    # 根节点开始遍历\n",
    "    for key in secondDict.keys():\n",
    "        # 判断子节点是不是dict, 求分枝的深度\n",
    "        if type(secondDict[key]) is dict:\n",
    "            thisDepth = 1 + getTreeDepth(secondDict[key])\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "        # 记录最大的分支深度\n",
    "        if thisDepth > maxDepth:\n",
    "            maxDepth = thisDepth\n",
    "    return maxDepth\n",
    "\n",
    "\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):\n",
    "    createPlot.ax1.annotate(nodeTxt, xy=parentPt,  xycoords='axes fraction', xytext=centerPt, textcoords='axes fraction', va=\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args)\n",
    "\n",
    "\n",
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]\n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]\n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\", rotation=30)\n",
    "\n",
    "\n",
    "def plotTree(myTree, parentPt, nodeTxt):\n",
    "    # 获取叶子节点的数量\n",
    "    numLeafs = getNumLeafs(myTree)\n",
    "    # 获取树的深度\n",
    "    # depth = getTreeDepth(myTree)\n",
    "\n",
    "    # 找出第1个中心点的位置，然后与 parentPt定点进行划线\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)\n",
    "    # print cntrPt\n",
    "    # 并打印输入对应的文字\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt)\n",
    "\n",
    "    firstSides = list(myTree.keys())\n",
    "    firstStr = firstSides[0]\n",
    "    # 可视化Node分支点\n",
    "    plotNode(firstStr, cntrPt, parentPt, decisionNode)\n",
    "    # 根节点的值\n",
    "    secondDict = myTree[firstStr]\n",
    "    # y值 = 最高点-层数的高度[第二个节点位置]\n",
    "    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD\n",
    "    for key in secondDict.keys():\n",
    "        # 判断该节点是否是Node节点\n",
    "        if type(secondDict[key]) is dict:\n",
    "            # 如果是就递归调用[recursion]\n",
    "            plotTree(secondDict[key], cntrPt, str(key))\n",
    "        else:\n",
    "            # 如果不是，就在原来节点一半的地方找到节点的坐标\n",
    "            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW\n",
    "            # 可视化该节点位置\n",
    "            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)\n",
    "            # 并打印输入对应的文字\n",
    "            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD\n",
    "\n",
    "\n",
    "def createPlot(inTree):\n",
    "    # 创建一个figure的模版\n",
    "    fig = plt.figure(1, facecolor='blue')\n",
    "    fig.clf()\n",
    "\n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    # 表示创建一个1行，1列的图，createPlot.ax1 为第 1 个子图，\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)\n",
    "\n",
    "    plotTree.totalW = float(getNumLeafs(inTree))\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))\n",
    "    # 半个节点的长度\n",
    "    plotTree.xOff = -0.5/plotTree.totalW\n",
    "    plotTree.yOff = 1.0\n",
    "    plotTree(inTree, (0.5, 1.0), '')\n",
    "    plt.show()\n",
    "\n",
    "# # 测试画图\n",
    "# def createPlot():\n",
    "#     fig = plt.figure(1, facecolor='white')\n",
    "#     fig.clf()\n",
    "#     # ticks for demo puropses\n",
    "#     createPlot.ax1 = plt.subplot(111, frameon=False)\n",
    "#     plotNode('a decision node', (0.5, 0.1), (0.1, 0.5), decisionNode)\n",
    "#     plotNode('a leaf node', (0.8, 0.1), (0.3, 0.8), leafNode)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# 测试数据集\n",
    "def retrieveTree(i):\n",
    "    listOfTrees = [\n",
    "        {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}},\n",
    "        {'no surfacing': {0: 'no', 1: {'flippers': {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'}}}}\n",
    "    ]\n",
    "    return listOfTrees[i]\n",
    "\n",
    "\n",
    "# myTree = retrieveTree(1)\n",
    "# createPlot(myTree)\n",
    "    \n",
    "createPlot(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. 测试算法**：使用决策树执行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(inputTree, featLabels, testVec):\n",
    "    \"\"\"classify(给输入的节点，进行分类)\n",
    "    Args:\n",
    "        inputTree  决策树模型\n",
    "        featLabels Feature标签对应的名称\n",
    "        testVec    测试输入的数据\n",
    "    Returns:\n",
    "        classLabel 分类的结果值，需要映射label才能知道名称\n",
    "    \"\"\"\n",
    "    # 获取tree的根节点对于的key值 \n",
    "    firstSides = list(inputTree.keys())\n",
    "    firstStr = firstSides[0] \n",
    "    # 通过key得到根节点对应的value\n",
    "    secondDict = inputTree[firstStr]\n",
    "    # 判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    # 测试数据，找到根节点对应的label位置，也就知道从输入的数据的第几位来开始分类\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    print('+++', firstStr, 'xxx', secondDict, '---', key, '>>>', valueOfFeat)\n",
    "    # 判断分枝是否结束: 判断valueOfFeat是否是dict类型\n",
    "    if isinstance(valueOfFeat, dict):\n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else:\n",
    "        classLabel = valueOfFeat\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ no surfacing xxx {0: 'no', 1: {'flippers': {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'}}} --- 1 >>> {'flippers': {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'}}\n",
      "+++ flippers xxx {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'} --- 1 >>> no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(myTree, classL, [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. 使用算法**：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义\n",
    "\n",
    "**保存树的数据结构，以便下次无需重新构建树**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# 存储树\n",
    "def storeTree(inputTree, filename):\n",
    "    fw = open(filename, 'wb+')\n",
    "    pickle.dump(inputTree, fw)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载树\n",
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename)\n",
    "    return pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storeTree(myTree, 'resource/DecisionTree/classifierStorage.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实践2： 使用决策树预测隐形眼镜类型\n",
    "\n",
    "#### 项目概述\n",
    "\n",
    "隐形眼镜类型包括硬材质、软材质以及不适合佩戴隐形眼镜。我们需要使用决策树预测患者需要佩戴的隐形眼镜类型。\n",
    "\n",
    "#### 开发流程\n",
    "\n",
    "1. 收集数据：提供的文本文件\n",
    "2. 准备数据：解析 tab 键分割的数据行\n",
    "3. 分析数据：快速检查数据，确保正确地解析数据内容，使用 createPlot() 函数绘制最终的树形图\n",
    "4. 训练算法：使用 createTree() 函数\n",
    "5. 测试算法：编写测试函数，验证决策树是否可以正确分类给定的数据实例\n",
    "6. 使用算法：存储树的数据结构，以便下次使用时无需重新构建树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 收集数据**：提供的文本文件\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
